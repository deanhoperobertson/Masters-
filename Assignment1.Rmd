---
title: "SL Assigment 1"
output: html_notebook
---
# Assignment 1
load data
```{r}
rm(list = ls())

library(GGally)
library(ISLR)
library(glmnet)
library(leaps)

#load data
data<-read.table('Assignment_1_Data.txt', h = T)

#summary of the data
summary(data)

#Split up training and test data
train_data = data[1:300,] #75%
test_data = data[-(1:300),] #25%
```
Null Model
```{r}
#NUll model
Null_mean = function(data){
  mse = NULL
  n = length(data$Balance)
  mean_balance = mean(data$Balance)
  for (i in 1:n){
  mse[i] = (data$Balance[i] - mean_balance)^2
  }
  temp = sum(mse)/n
  return(temp)
}
#Null model has a MSE of 32.06
Null_mean(train_data)
Null_mean(test_data)
```
1) Straight forward linear Regression

```{r}
#First model with all variables
fit1_train = lm(Balance~.,data=train_data)

#predict of test data
pred_test = predict(fit1_train, test_data)
pred_train = predict(fit1_train, train_data)

#compute mse
mse_test = mean((test_data$Balance-pred_test)^2)
mse_train = mean((train_data$Balance-pred_train)^2)
```
# Backwards Selection
```{r}
#removing Gender and Ethnicity
fit2_train = lm(Balance~.-Gender -Ethnicity,data=train_data)
summary(fit2_train)

#calculat the new MSE
pred_test2 = predict(fit2_train, test_data)
mse_test2 = mean((test_data$Balance-pred_test2)^2)

#correlation matrix show the high correlation between Rating and Limit - can assume Collinearity 
cor(data$Limit,data$Rating)
fit3_train = lm(Balance~.-Gender -Ethnicity - Rating - Limit,data=train_data)

#calculat the new MSE
pred_test3 = predict(fit3_train, test_data)
pred_train3 = predict(fit3_train, train_data)

mse_test3 = mean((test_data$Balance-pred_test3)^2)
mse_train3 = mean((train_data$Balance-pred_train3)^2)
```
1) Subsect Selection

```{r}
regfit.full=regsubsets (Balance ~.,data=train_data,nvmax =11)
reg.summary = summary(regfit.full)

#optimal number of variables (5 varibales)
which.min(reg.summary$cp)
which.max(reg.summary$adjr2)
which.min(reg.summary$bic)

#can plot Mallow's CP/BIC/AdjR2 across the all models
par(mfrow =c(1,3))
plot(reg.summary$cp ,xlab=" Number of Variables ",ylab="CP",type = 'b')
points (5, reg.summary$cp[5], col ="red",cex =2, pch =20)
abline(v=5,col='red', lty=2)
plot(reg.summary$adjr2 ,xlab=" Number of Variables ",ylab="AdjR2",type = 'b')
points (5, reg.summary$adjr2[5], col ="red",cex =2, pch =20)
abline(v=5,col='red', lty=2)
plot(reg.summary$bic ,xlab =" Number of Variables ",ylab=" BIC",type="b")
points (5, reg.summary$bic[5], col ="red",cex =2, pch =20)
abline(v=5,col='red', lty=2)

#another plot
plot(regfit.full ,scale ="Cp")
plot(regfit.full ,scale ="adjr2")
plot(regfit.full ,scale ="bic")

coef(regfit.full ,5)

#CROSS VALIDATION
#define prediction function for subsect
predict.regsubsets =function (object ,newdata ,id ,...){
  form=as.formula(object$call [[2]])
  mat=model.matrix (form ,newdata )
  coefi =coef(object ,id=id)
  xvars =names (coefi )
  mat[,xvars ]%*% coefi
}


#Can Also evaluate using Cross Validation
k=10
set.seed (1)
folds=sample(1:k,nrow(train_data),replace =TRUE)

table(folds)
cv.errors =matrix(NA ,k,11)

for(j in 1:k){
  best.fit=regsubsets(Balance~.,data=train_data[folds!=j,],nvmax=11)
  for(i in 1:11){
    pred=predict.regsubsets(best.fit ,train_data[folds ==j,],id=i)
    cv.errors[j,i]= mean((train_data$Balance[folds==j]-pred)^2)
  }
}

mean.cv.errors =apply(cv.errors ,2, mean)
which.min(mean.cv.errors)

plot(mean.cv.errors ,type='b')
points(5,mean.cv.errors[5], col ='red', pch=20, cex =2)
abline(v=5,col='red', lty=2)

#extract the coefficents
reg.best=regsubsets(Balance~.,data=data , nvmax =11)
coef(reg.best ,5)

# only use teh five variables recommended by the subset selction
sub_fit = lm(Balance~ Income + Age + Education + Student + Married,data=train_data)

#test and train
pred_test_sub = predict(sub_fit, test_data)
pred_train_sub = predict(sub_fit, train_data)

#compute mse
mse_test_sub = mean((test_data$Balance-pred_test_sub)^2)
mse_train_sub = mean((train_data$Balance-pred_train_sub)^2)
mse_test_sub
mse_train_sub
```
# Shrinkage Methods

1) Ridge Regression
```{r}
x=model.matrix(Balance~.-1,train_data)
x_test =model.matrix(Balance~.-1,test_data)
y=train_data$Balance
y_test = test_data$Balance

#Ridge: alpha=0 abd LASSO: alpha=1
ridge.mod =glmnet(x,y,alpha=0)

#plot
plot(ridge.mod,xvar = "lambda" ,label = TRUE)

#cross validation
cv.ridge = cv.glmnet(x,y,alpha =0)
plot(cv.ridge)

bestlam=cv.ridge$lambda.min

ridge.test=predict(ridge.mod,s=bestlam,x_test)
ridge.train=predict(ridge.mod,s=bestlam,x)

mse_reg_test = mean((y_test-ridge.test)^2)
mse_reg_train = mean((y-ridge.train)^2)
mse_reg_test
mse_reg_train
??svm
```

2) LASSO

```{r}
lasso.mod =glmnet(x,y,alpha =1)
plot(lasso.mod,xvar = "lambda" ,label = TRUE)

set.seed (1)
cv.out =cv.glmnet(x,y,alpha =1)
plot(cv.out)
xbestlam =cv.out$lambda.min

lasso_train =predict(lasso.mod,s=xbestlam,x)
lasso_test =predict(lasso.mod,s=xbestlam,x_test)

mse_lass_test = mean((y_test-lasso_test)^2)
mse_lass_train = mean((y-lasso_train)^2)
mse_lass_train
mse_lass_test

coef(cv.out)

```
Principal Components Regression
```{r}
library (pls)
set.seed(1)
pcr.fit=pcr(Balance~., data=train_data,scale=TRUE ,validation ="CV")
summary(pcr.fit)

validationplot(pcr.fit ,val.type="MSEP")

pcr.pred_test=predict (pcr.fit ,test_data, ncomp =10)
pcr.pred_train=predict (pcr.fit ,train_data, ncomp =10)

mse_prc_test = mean((test_data$Balance -pcr.pred_test)^2)
mse_prc_train = mean((train_data$Balance -pcr.pred_train)^2)

#fit on to full data
pcr.fit=pcr(y~x,scale =TRUE ,ncomp =10)
pcr.pred=predict (pcr.fit ,data, ncomp =10)
mean((pcr.pred -Balance)^2)

coef(pcr.fit)
```



