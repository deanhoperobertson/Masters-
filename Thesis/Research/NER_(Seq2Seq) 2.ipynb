{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER (Seq2Seq).ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [Root]",
      "language": "python",
      "name": "Python [Root]"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "UnCgNSblIXCs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import pandas as pd\n",
        "\n",
        "#most common enetity per word\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "#model building - tree classification\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "#labeling\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.pipeline import Pipeline #Sequentially apply a list of transforms\n",
        "\n",
        "#data = pd.read_csv(\"ner_dataset.csv\", encoding=\"latin1\")\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/deanhoperobertson/Masters-/master/Thesis/ner_dataset.csv\"\n",
        "data = pd.read_csv(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eji2GiKQIXCx",
        "colab_type": "code",
        "outputId": "28e1120b-cf75-475c-b1dc-1095653faf3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "cell_type": "code",
      "source": [
        "data = data.fillna(method=\"ffill\")\n",
        "data.tail(10)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1048565</th>\n",
              "      <td>Sentence: 47958</td>\n",
              "      <td>impact</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048566</th>\n",
              "      <td>Sentence: 47958</td>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048567</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>Indian</td>\n",
              "      <td>JJ</td>\n",
              "      <td>B-gpe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048568</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>forces</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048569</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>said</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048570</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>they</td>\n",
              "      <td>PRP</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048571</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>responded</td>\n",
              "      <td>VBD</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048572</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>to</td>\n",
              "      <td>TO</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048573</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1048574</th>\n",
              "      <td>Sentence: 47959</td>\n",
              "      <td>attack</td>\n",
              "      <td>NN</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Sentence #       Word  POS    Tag\n",
              "1048565  Sentence: 47958     impact   NN      O\n",
              "1048566  Sentence: 47958          .    .      O\n",
              "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
              "1048568  Sentence: 47959     forces  NNS      O\n",
              "1048569  Sentence: 47959       said  VBD      O\n",
              "1048570  Sentence: 47959       they  PRP      O\n",
              "1048571  Sentence: 47959  responded  VBD      O\n",
              "1048572  Sentence: 47959         to   TO      O\n",
              "1048573  Sentence: 47959        the   DT      O\n",
              "1048574  Sentence: 47959     attack   NN      O"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "0n2BH1q0IXC2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = list(set(data[\"Word\"].values))\n",
        "words.append(\"ENDPAD\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wXG1KSKRIXC4",
        "colab_type": "code",
        "outputId": "c90839a0-b70e-43cf-8376-182d8f90974b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "#number of words\n",
        "n_words = len(words); n_words"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35179"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "ryoI2pI0IXC_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "So we have 47959 sentences containing 35178 different words with 17 different tags. "
      ]
    },
    {
      "metadata": {
        "id": "QLMGqV64IXDA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#define a class to retrieve sentences and labels\n",
        "\n",
        "class SentenceGetter(object):\n",
        "    \n",
        "    def __init__(self, data):\n",
        "        self.n_sent = 1\n",
        "        self.data = data\n",
        "        self.empty = False\n",
        "    \n",
        "    def get_next(self):\n",
        "        try:\n",
        "            s = self.data[self.data[\"Sentence #\"] == \"Sentence: {}\".format(self.n_sent)]\n",
        "            self.n_sent += 1\n",
        "            return s[\"Word\"].values.tolist(), s[\"POS\"].values.tolist(), s[\"Tag\"].values.tolist()    \n",
        "        except:\n",
        "            self.empty = True\n",
        "            return None, None, None\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KhtRgyOaIXDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "getter = SentenceGetter(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wo_8JvoaIXDE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sent, pos, tag = getter.get_next()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wlnt0cxBIXDH",
        "colab_type": "code",
        "outputId": "917cb719-3430-448b-b3f9-4100f63cdd83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "print(sent);print(pos); print(tag)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Thousands', 'of', 'demonstrators', 'have', 'marched', 'through', 'London', 'to', 'protest', 'the', 'war', 'in', 'Iraq', 'and', 'demand', 'the', 'withdrawal', 'of', 'British', 'troops', 'from', 'that', 'country', '.']\n",
            "['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'IN', 'NNP', 'CC', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'NN', '.']\n",
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PdSGTyQDZEBU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Base-line Model \n",
        "\n",
        "- most common entity tag per word"
      ]
    },
    {
      "metadata": {
        "id": "eTdweD-FIXDL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class MemoryTagger(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        '''\n",
        "        Expects a list of words as X and a list of tags as y.\n",
        "        '''\n",
        "        voc = {}\n",
        "        self.tags = []\n",
        "        for x, t in zip(X, y):\n",
        "            if t not in self.tags:\n",
        "                self.tags.append(t)\n",
        "            if x in voc:\n",
        "                if t in voc[x]:\n",
        "                    voc[x][t] += 1\n",
        "                else:\n",
        "                    voc[x][t] = 1\n",
        "            else:\n",
        "                voc[x] = {t: 1}\n",
        "        self.memory = {}\n",
        "        for k, d in voc.items():\n",
        "            self.memory[k] = max(d, key=d.get)\n",
        "    \n",
        "    def predict(self, X, y=None):\n",
        "        '''\n",
        "        Predict the the tag from memory. If word is unknown, predict 'O'.\n",
        "        '''\n",
        "        return [self.memory.get(x, 'O') for x in X]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_D5v5ozsIXDN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tagger = MemoryTagger()\n",
        "\n",
        "tagger.fit(sent, tag)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6CG-l6XVIXDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "81543df5-1497-427c-ba0a-5d7084d563e9"
      },
      "cell_type": "code",
      "source": [
        "print(tagger.predict(sent))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "03BBMjZoIXDW",
        "colab_type": "code",
        "outputId": "02a1c460-de51-4ff7-a80c-dfe2431171a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "tagger.tags"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-geo', 'B-gpe']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "1IwuHCbxIXDY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#cerate a list with all the words and \n",
        "words = data[\"Word\"].values.tolist()\n",
        "tags = data[\"Tag\"].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PWDTrf-BIXDc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = cross_val_predict(estimator=MemoryTagger(), X=words, y=tags, cv=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YOEtFKBkIXDg",
        "colab_type": "code",
        "outputId": "053e9d2f-5e01-4b92-b32d-4e4db859b458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "report = classification_report(y_pred=pred, y_true=tags)\n",
        "print(report)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.28      0.07      0.11       402\n",
            "       B-eve       0.52      0.25      0.33       308\n",
            "       B-geo       0.78      0.84      0.81     37644\n",
            "       B-gpe       0.94      0.93      0.94     15870\n",
            "       B-nat       0.41      0.28      0.33       201\n",
            "       B-org       0.65      0.49      0.56     20143\n",
            "       B-per       0.77      0.65      0.71     16990\n",
            "       B-tim       0.87      0.77      0.82     20333\n",
            "       I-art       0.04      0.01      0.02       297\n",
            "       I-eve       0.35      0.12      0.18       253\n",
            "       I-geo       0.72      0.59      0.65      7414\n",
            "       I-gpe       0.62      0.45      0.52       198\n",
            "       I-nat       0.00      0.00      0.00        51\n",
            "       I-org       0.69      0.53      0.60     16784\n",
            "       I-per       0.74      0.64      0.69     17251\n",
            "       I-tim       0.56      0.13      0.21      6528\n",
            "           O       0.97      0.99      0.98    887908\n",
            "\n",
            "   micro avg       0.95      0.95      0.95   1048575\n",
            "   macro avg       0.58      0.46      0.50   1048575\n",
            "weighted avg       0.94      0.95      0.94   1048575\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vhzym9o2YyfI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Simple Machine Learning (Classification Trees)**"
      ]
    },
    {
      "metadata": {
        "id": "OjOSmXEkIXDr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#feature engineering\n",
        "\n",
        "def feature_map(word):\n",
        "    '''Simple feature map.'''\n",
        "    return np.array([word.istitle(), word.islower(), word.isupper(), len(word),\n",
        "                     word.isdigit(),  word.isalpha()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pv6KF9CCIXDs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#extract feature per word\n",
        "words = [feature_map(w) for w in data[\"Word\"].values.tolist()]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y-YJV--FIXDv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = cross_val_predict(RandomForestClassifier(n_estimators=20),\n",
        "                         X=words, y=tags, cv=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JowtjFzGIXDx",
        "colab_type": "code",
        "outputId": "2ad1e5b5-fe72-4277-a53c-ac7dc335f4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        }
      },
      "cell_type": "code",
      "source": [
        "report = classification_report(y_pred=pred, y_true=tags)\n",
        "print(report)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.00      0.00      0.00       402\n",
            "       B-eve       0.00      0.00      0.00       308\n",
            "       B-geo       0.26      0.80      0.40     37644\n",
            "       B-gpe       0.25      0.03      0.05     15870\n",
            "       B-nat       0.00      0.00      0.00       201\n",
            "       B-org       0.65      0.17      0.27     20143\n",
            "       B-per       0.97      0.20      0.33     16990\n",
            "       B-tim       0.29      0.32      0.30     20333\n",
            "       I-art       0.00      0.00      0.00       297\n",
            "       I-eve       0.00      0.00      0.00       253\n",
            "       I-geo       0.00      0.00      0.00      7414\n",
            "       I-gpe       0.00      0.00      0.00       198\n",
            "       I-nat       0.00      0.00      0.00        51\n",
            "       I-org       0.36      0.03      0.06     16784\n",
            "       I-per       0.47      0.02      0.04     17251\n",
            "       I-tim       0.50      0.06      0.11      6528\n",
            "           O       0.97      0.98      0.97    887908\n",
            "\n",
            "   micro avg       0.87      0.87      0.87   1048575\n",
            "   macro avg       0.28      0.15      0.15   1048575\n",
            "weighted avg       0.88      0.87      0.86   1048575\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FOb6Xf7tcEKO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a terrible score and indicates that this model has unperformed - this is expected seeing as the random forest classification algorithm does not have much infomation to use. "
      ]
    },
    {
      "metadata": {
        "id": "2Ar0NFjwIXD0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class FeatureTransformer(BaseEstimator, TransformerMixin):\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.memory_tagger = MemoryTagger()\n",
        "        self.tag_encoder = LabelEncoder()\n",
        "        self.pos_encoder = LabelEncoder()\n",
        "        \n",
        "    def fit(self, X, y):\n",
        "        words = X[\"Word\"].values.tolist()\n",
        "        self.pos = X[\"POS\"].values.tolist()\n",
        "        tags = X[\"Tag\"].values.tolist()\n",
        "        self.memory_tagger.fit(words, tags)\n",
        "        self.tag_encoder.fit(tags)\n",
        "        self.pos_encoder.fit(self.pos)\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        def pos_default(p):\n",
        "            if p in self.pos:\n",
        "                return self.pos_encoder.transform([p])[0]\n",
        "            else:\n",
        "                return -1\n",
        "        \n",
        "        pos = X[\"POS\"].values.tolist()\n",
        "        words = X[\"Word\"].values.tolist()\n",
        "        out = []\n",
        "        for i in range(len(words)):\n",
        "            w = words[i]\n",
        "            p = pos[i]\n",
        "            if i < len(words) - 1:\n",
        "                wp = self.tag_encoder.transform(self.memory_tagger.predict([words[i+1]]))[0]\n",
        "                posp = pos_default(pos[i+1])\n",
        "            else:\n",
        "                wp = self.tag_encoder.transform(['O'])[0]\n",
        "                posp = pos_default(\".\")\n",
        "            if i > 0:\n",
        "                if words[i-1] != \".\":\n",
        "                    wm = self.tag_encoder.transform(self.memory_tagger.predict([words[i-1]]))[0]\n",
        "                    posm = pos_default(pos[i-1])\n",
        "                else:\n",
        "                    wm = self.tag_encoder.transform(['O'])[0]\n",
        "                    posm = pos_default(\".\")\n",
        "            else:\n",
        "                posm = pos_default(\".\")\n",
        "                wm = self.tag_encoder.transform(['O'])[0]\n",
        "            out.append(np.array([w.istitle(), w.islower(), w.isupper(), len(w), w.isdigit(), w.isalpha(),\n",
        "                                 self.tag_encoder.transform(self.memory_tagger.predict([w]))[0],\n",
        "                                 pos_default(p), wp, wm, posp, posm]))\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1-MjSjNJIXD1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pred = cross_val_predict(Pipeline([(\"feature_map\", FeatureTransformer()), \n",
        "                                   (\"clf\", RandomForestClassifier(n_estimators=20, n_jobs=3))]),\n",
        "                         X=data, y=tags, cv=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iC_wUSTAIXD4",
        "colab_type": "code",
        "outputId": "b3b1691b-1c20-4738-fb0c-a1f133abd840",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "cell_type": "code",
      "source": [
        "report = classification_report(y_pred=pred, y_true=tags)\n",
        "print(report)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-art       0.19      0.09      0.12       402\n",
            "       B-eve       0.38      0.27      0.32       308\n",
            "       B-geo       0.83      0.86      0.84     37644\n",
            "       B-gpe       0.98      0.93      0.95     15870\n",
            "       B-nat       0.21      0.22      0.22       201\n",
            "       B-org       0.73      0.64      0.68     20143\n",
            "       B-per       0.82      0.75      0.78     16990\n",
            "       B-tim       0.89      0.80      0.84     20333\n",
            "       I-art       0.04      0.02      0.03       297\n",
            "       I-eve       0.30      0.15      0.20       253\n",
            "       I-geo       0.76      0.67      0.71      7414\n",
            "       I-gpe       0.74      0.45      0.56       198\n",
            "       I-nat       0.44      0.22      0.29        51\n",
            "       I-org       0.73      0.67      0.70     16784\n",
            "       I-per       0.85      0.75      0.80     17251\n",
            "       I-tim       0.81      0.53      0.64      6528\n",
            "           O       0.98      0.99      0.99    887908\n",
            "\n",
            "   micro avg       0.96      0.96      0.96   1048575\n",
            "   macro avg       0.63      0.53      0.57   1048575\n",
            "weighted avg       0.96      0.96      0.96   1048575\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YrzZvrioQw1Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}