{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BiLSTM Simple.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deanhoperobertson/Masters-/blob/master/Thesis/BiLSTM_Simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "0MT3CGytpRUx",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": "OK"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "01715a87-2e73-4ff4-d92e-8e7f5fab5292"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('mylib.py','wb').write(src)\n",
        "import mylib"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3abb22d7-5544-463b-8fa2-b878e88d6ee2\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-3abb22d7-5544-463b-8fa2-b878e88d6ee2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving prepro.py to prepro (1).py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RkIyG0W9r6Bk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "2fd11032-9b3d-4afc-c5f5-829f2abac71a"
      },
      "cell_type": "code",
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn_crfsuite in /usr/local/lib/python3.6/dist-packages (0.3.6)\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.28.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.3)\n",
            "Requirement already satisfied: python-crfsuite>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.9.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.11.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O5VcsMj9pSGv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#cusotm packages\n",
        "from prepro import readfile, readstring\n",
        "\n",
        "#keras and tensorflow packages\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Model, Input\n",
        "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "\n",
        "#evaluation\n",
        "from sklearn_crfsuite.metrics import flat_classification_report,flat_f1_score,flat_precision_score\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZCjP9f36pYNF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import data from my github repo\n",
        "train_url = \"https://raw.githubusercontent.com/deanhoperobertson/Masters-/master/Thesis/Code/Data/train.txt\"\n",
        "test_url = \"https://raw.githubusercontent.com/deanhoperobertson/Masters-/master/Thesis/Code/Data/test.txt\"\n",
        "train = urllib.request.urlopen(train_url).read()\n",
        "test = urllib.request.urlopen(test_url).read()\n",
        "train = train.decode('utf-8')\n",
        "test = test.decode('utf-8')\n",
        "\n",
        "#preproces the txt file\n",
        "train = readstring(train)\n",
        "test = readstring(test)\n",
        "\n",
        "#create corpus\n",
        "corpus = train.copy()\n",
        "corpus.extend(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8cRc4YJ6peM8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "words = []\n",
        "tags = []\n",
        "for sentence in corpus:\n",
        "    for word in sentence:\n",
        "        words.append(word[0])\n",
        "        tags.append(word[1])       "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JkxgfXW4pkld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6e49556b-7bf4-4ba8-e8ba-2f163e6fdde3"
      },
      "cell_type": "code",
      "source": [
        "words=list(set(words))\n",
        "n_words = len(words)\n",
        "print(\"Number of words in the dataset: \", n_words)\n",
        "tags = list(set(tags))\n",
        "n_tags = len(tags)\n",
        "print(\"Number of Labels: \", n_tags)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in the dataset:  27316\n",
            "Number of Labels:  9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ka8mtItvpmC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a45464f9-704a-43af-d3b1-a163f2625361"
      },
      "cell_type": "code",
      "source": [
        "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
        "word2idx[\"UNK\"] = 1 # Unknown words\n",
        "word2idx[\"PAD\"] = 0 # Padding\n",
        "# Vocabulary Key:token_index -> Value:word\n",
        "idx2word = {i: w for w, i in word2idx.items()}\n",
        "print(\"The word 'rejects' is identified by the index: {}\".format(word2idx[\"rejects\"]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The word 'rejects' is identified by the index: 27066\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TXJ6q4kqppTY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a3b9fa29-107f-48ae-e0ec-046545d25b57"
      },
      "cell_type": "code",
      "source": [
        "# The first entry is reserved for PAD\n",
        "tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
        "tag2idx[\"PAD\"] = 0\n",
        "# Vocabulary Key:tag_index -> Value:Label/Tag\n",
        "idx2tag = {i: w for w, i in tag2idx.items()}\n",
        "print(\"The labels B-LOC (location) is identified by the index: {}\".format(tag2idx[\"B-LOC\"]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The labels B-LOC (location) is identified by the index: 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z55mbHEJ0uOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "0a9a0868-b0dd-43de-f980-5d671e0c19e2"
      },
      "cell_type": "code",
      "source": [
        "tag2idx"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'B-LOC': 8,\n",
              " 'B-MISC': 5,\n",
              " 'B-ORG': 4,\n",
              " 'B-PER': 3,\n",
              " 'I-LOC': 6,\n",
              " 'I-MISC': 9,\n",
              " 'I-ORG': 2,\n",
              " 'I-PER': 1,\n",
              " 'O': 7,\n",
              " 'PAD': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "uy3WPErbqFcR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "42c7c778-16bd-4f6c-f5f9-d1d39b44ad9e"
      },
      "cell_type": "code",
      "source": [
        "#Find the maxium length of the all the sentences in the corpus\n",
        "length = []\n",
        "for sentence in corpus:\n",
        "  length.append(len(sentence))\n",
        "\n",
        "MAX_LEN= max(length)\n",
        "print(\"The maxium length of sentence is:\",max(length))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The maxium length of sentence is: 124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pzRk_4UEqI_j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "7bbb807f-9166-4191-c852-65e9b8cbe866"
      },
      "cell_type": "code",
      "source": [
        "# Convert each sentence from list of Token to list of word_index\n",
        "X = [[word2idx[w[0]] for w in s] for s in train]\n",
        "\n",
        "# Padding each sentence to have the same lenght\n",
        "X = pad_sequences(maxlen=MAX_LEN, sequences=X, padding=\"post\", value=word2idx[\"PAD\"])\n",
        "X"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17334, 27066, 16442, ...,     0,     0,     0],\n",
              "       [26781, 19924,     0, ...,     0,     0,     0],\n",
              "       [ 5157, 23435,     0, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [25902,  9027, 18349, ...,     0,     0,     0],\n",
              "       [10792, 26450,     0, ...,     0,     0,     0],\n",
              "       [ 4239,   617, 10029, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "YFWL-5RyqRGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9cbebc09-eb66-445b-80b8-7ad25dfcaf61"
      },
      "cell_type": "code",
      "source": [
        "# Convert Tag/Label to tag_index\n",
        "y = [[tag2idx[w[1]] for w in s] for s in train]\n",
        "\n",
        "# Padding each sentence to have the same lenght\n",
        "y = pad_sequences(maxlen=MAX_LEN, sequences=y, padding=\"post\", value=tag2idx[\"PAD\"])\n",
        "y"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4, 7, 5, ..., 0, 0, 0],\n",
              "       [3, 1, 0, ..., 0, 0, 0],\n",
              "       [8, 7, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [4, 7, 4, ..., 0, 0, 0],\n",
              "       [7, 7, 0, ..., 0, 0, 0],\n",
              "       [4, 7, 4, ..., 0, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "VliiPoLPqVXu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# One-Hot encode\n",
        "y = [to_categorical(i, num_classes=n_tags+1) for i in y]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a_ivKMgcqW3B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#split into test and train subsets\n",
        "X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Jyrz9iIFqYbI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c746e9d-c0e8-4e87-8fa4-30b11114b60a"
      },
      "cell_type": "code",
      "source": [
        "X_tr.shape, X_te.shape, np.array(y_tr).shape, np.array(y_te).shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((12636, 124), (1405, 124), (12636, 124, 10), (1405, 124, 10))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "k_6ByIzUqZjK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "2cc8aff2-8832-4213-9ad2-8d38926ce9c5"
      },
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "EMBEDDING=40\n",
        "\n",
        "input = Input(shape=(MAX_LEN,))\n",
        "model = Embedding(input_dim=n_words+2, output_dim=EMBEDDING, # n_words + 2 (PAD & UNK)\n",
        "                  input_length=MAX_LEN, mask_zero=True)(input)\n",
        "\n",
        "model = Bidirectional(LSTM(units=50, return_sequences=True,\n",
        "                           recurrent_dropout=0.1))(model)\n",
        "\n",
        "out = TimeDistributed(Dense(10, activation=\"softmax\"))(model)\n",
        "model = Model(input, out)\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 124)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 124, 40)           1092720   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 124, 100)          36400     \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 124, 10)           1010      \n",
            "=================================================================\n",
            "Total params: 1,130,130\n",
            "Trainable params: 1,130,130\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V5sSolxN8FaF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Metrics(Callback):\n",
        "    \n",
        "    def on_train_begin(self, logs=None):\n",
        "        self.val_precisions = []\n",
        "        self.val_f1s = []\n",
        "        self.val_recalls = []\n",
        "    \n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
        "        val_targ = self.model.validation_data[1]\n",
        "        _val_precision = np.dot(val_targ, val_predict)/sum(val_predict)\n",
        "        _val_recall = np.dot(val_targ, val_predict)/sum(val_targ)\n",
        "        _val_f1 = (2*_val_precision*_val_recall)/(_val_precision + _val_recall)\n",
        "        self.val_precisions.append(_val_precision)\n",
        "        self.val_recalls.append(_val_recall)\n",
        "        self.val_f1s.append(_val_f1)\n",
        "        print(\" — val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
        "        return "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WEw6CxCP8m6l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "metrics=BinaryClassificationMetrics()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "owhFiQqNqcxq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "487446be-0ae2-404d-9e69-0336402af9e3"
      },
      "cell_type": "code",
      "source": [
        "%%time\n",
        "BATCH_SIZE = 500\n",
        "EPOCHS=20\n",
        "\n",
        "\n",
        "history = model.fit(X_tr, np.array(y_tr), batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.1, verbose=2)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11372 samples, validate on 1264 samples\n",
            "Epoch 1/10\n",
            " - 43s - loss: 0.0500 - acc: 0.9892 - val_loss: 0.1706 - val_acc: 0.9569\n",
            "Epoch 2/10\n",
            " - 43s - loss: 0.0425 - acc: 0.9906 - val_loss: 0.1695 - val_acc: 0.9554\n",
            "Epoch 3/10\n",
            " - 43s - loss: 0.0365 - acc: 0.9923 - val_loss: 0.1597 - val_acc: 0.9604\n",
            "Epoch 4/10\n",
            " - 43s - loss: 0.0309 - acc: 0.9935 - val_loss: 0.1593 - val_acc: 0.9600\n",
            "Epoch 5/10\n",
            " - 44s - loss: 0.0269 - acc: 0.9943 - val_loss: 0.1590 - val_acc: 0.9595\n",
            "Epoch 6/10\n",
            " - 44s - loss: 0.0234 - acc: 0.9951 - val_loss: 0.1574 - val_acc: 0.9611\n",
            "Epoch 7/10\n",
            " - 43s - loss: 0.0205 - acc: 0.9956 - val_loss: 0.1517 - val_acc: 0.9630\n",
            "Epoch 8/10\n",
            " - 43s - loss: 0.0181 - acc: 0.9962 - val_loss: 0.1526 - val_acc: 0.9642\n",
            "Epoch 9/10\n",
            " - 43s - loss: 0.0157 - acc: 0.9967 - val_loss: 0.1524 - val_acc: 0.9640\n",
            "Epoch 10/10\n",
            " - 43s - loss: 0.0139 - acc: 0.9971 - val_loss: 0.1514 - val_acc: 0.9640\n",
            "CPU times: user 13min 10s, sys: 1min 4s, total: 14min 15s\n",
            "Wall time: 7min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Itsrutsd_WnJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"model.1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8HH4d2cOwd9k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Evaluation\n",
        "\n",
        "#### Training Dataset"
      ]
    },
    {
      "metadata": {
        "id": "2QVC47ldqfc2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "c31a7654-fe3f-4a98-de70-700933bc867d"
      },
      "cell_type": "code",
      "source": [
        "# TRain Eval\n",
        "pred_cat = model.predict(X_tr)\n",
        "pred = np.argmax(pred_cat, axis=-1)\n",
        "y_tr_true = np.argmax(y_tr, -1)\n",
        "\n",
        "# Convert the index to tag\n",
        "pred_tag = [[idx2tag[i] for i in row] for row in pred]\n",
        "y_tr_true_tag = [[idx2tag[i] for i in row] for row in y_tr_true] \n",
        "\n",
        "report = flat_classification_report(y_pred=pred_tag, y_true=y_tr_true_tag)\n",
        "print(report)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.34      0.98      0.51      6440\n",
            "      B-MISC       0.53      0.96      0.68      3083\n",
            "       B-ORG       0.35      0.98      0.52      5701\n",
            "       B-PER       0.44      0.99      0.61      5904\n",
            "       I-LOC       0.13      0.94      0.23      1009\n",
            "      I-MISC       0.05      0.93      0.10      1048\n",
            "       I-ORG       0.16      0.96      0.28      3357\n",
            "       I-PER       0.16      0.99      0.27      4047\n",
            "           O       0.11      1.00      0.19    152163\n",
            "         PAD       0.00      0.00      0.00   1384112\n",
            "\n",
            "   micro avg       0.12      0.12      0.12   1566864\n",
            "   macro avg       0.23      0.87      0.34   1566864\n",
            "weighted avg       0.02      0.12      0.03   1566864\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5dmb6LI7wpzj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Test Dataset"
      ]
    },
    {
      "metadata": {
        "id": "reAA5DOrwsNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "7e58e74b-88d8-4c75-d9d7-c1b6bd99cdaf"
      },
      "cell_type": "code",
      "source": [
        "# TRain Eval\n",
        "pred_cat = model.predict(X_te)\n",
        "pred = np.argmax(pred_cat, axis=-1)\n",
        "y_te_true = np.argmax(y_te, -1)\n",
        "\n",
        "# Convert the index to tag\n",
        "pred_tag = [[idx2tag[i] for i in row] for row in pred]\n",
        "y_te_true_tag = [[idx2tag[i] for i in row] for row in y_te_true] \n",
        "\n",
        "report = flat_classification_report(y_pred=pred_tag, y_true=y_te_true_tag)\n",
        "print(report)"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       B-LOC       0.26      0.88      0.41       700\n",
            "      B-MISC       0.33      0.84      0.47       355\n",
            "       B-ORG       0.21      0.87      0.33       620\n",
            "       B-PER       0.32      0.92      0.48       696\n",
            "       I-LOC       0.14      0.69      0.24       148\n",
            "      I-MISC       0.03      0.82      0.06       107\n",
            "       I-ORG       0.09      0.81      0.16       347\n",
            "       I-PER       0.09      0.89      0.16       481\n",
            "           O       0.11      0.99      0.20     17415\n",
            "         PAD       0.00      0.00      0.00    153351\n",
            "\n",
            "   micro avg       0.12      0.12      0.12    174220\n",
            "   macro avg       0.16      0.77      0.25    174220\n",
            "weighted avg       0.02      0.12      0.03    174220\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QSsUr25F2hOc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}