{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseLine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Custom models\n",
    "from prepro import readfile, readstring, get_sentence, is_number, extract_words\n",
    "\n",
    "\n",
    "#most common entity per word\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data from my github repo\n",
    "train = readfile(\"train.txt\")\n",
    "corpus = train.copy()\n",
    "test = readfile(\"test.txt\")\n",
    "\n",
    "#create corpus\n",
    "corpus.extend(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "tags = []\n",
    "for sentence in corpus:\n",
    "    for word in sentence:\n",
    "        words.append(word[0])\n",
    "        tags.append(word[1])           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Tockenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the dataset:  27316\n",
      "Number of tags in the dataset:  9\n"
     ]
    }
   ],
   "source": [
    "words=list(words)\n",
    "n_words = len(set(words))\n",
    "n_tags = len(set(tags))\n",
    "\n",
    "print(\"Number of words in the dataset: \", n_words)\n",
    "print(\"Number of tags in the dataset: \", n_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word 'rejects' is identified by the index: 218128\n"
     ]
    }
   ],
   "source": [
    "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1 # Unknown words\n",
    "word2idx[\"PAD\"] = 0 # Padding\n",
    "# Vocabulary Key:token_index -> Value:word\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "print(\"The word 'rejects' is identified by the index: {}\".format(word2idx[\"rejects\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The labels B-LOC (location) is identified by the index: 250026\n"
     ]
    }
   ],
   "source": [
    "# The first entry is reserved for PAD\n",
    "tag2idx = {t: i+1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "# Vocabulary Key:tag_index -> Value:Label/Tag\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}\n",
    "print(\"The labels B-LOC (location) is identified by the index: {}\".format(tag2idx[\"B-LOC\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(word_list):\n",
    "    new_list= []\n",
    "    for word in word_list:\n",
    "        if is_number(word2idx[word]):\n",
    "            new_list.append(word2idx[word])\n",
    "    else:\n",
    "        None\n",
    "    return(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training set\n",
    "train_words, train_tags = extract_words(train)\n",
    "\n",
    "#tokenize words into tokens\n",
    "tr_words = tokenize(train_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MemoryTagger(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        '''\n",
    "        Expects a list of words as X and a list of tags as y.\n",
    "        '''\n",
    "        voc = {}\n",
    "        self.tags = []\n",
    "        for x, t in zip(X, y):\n",
    "            if t not in self.tags:\n",
    "                self.tags.append(t)\n",
    "            if x in voc:\n",
    "                if t in voc[x]:\n",
    "                    voc[x][t] += 1\n",
    "                else:\n",
    "                    voc[x][t] = 1\n",
    "            else:\n",
    "                voc[x] = {t: 1}\n",
    "        self.memory = {}\n",
    "        for k, d in voc.items():\n",
    "            self.memory[k] = max(d, key=d.get)\n",
    "    \n",
    "    def predict(self, X, y=None):\n",
    "        '''\n",
    "        Predict the the tag from memory. If word is unknown, predict 'O'.\n",
    "        '''\n",
    "        return [self.memory.get(x, 'O') for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit model to NER training set \n",
    "tagger = MemoryTagger()\n",
    "tagger.fit(tr_words, train_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']\n",
      "['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "#predict the first sentence using the base model\n",
    "print(get_sentence(train,1))\n",
    "print(tagger.predict(tokenize(get_sentence(train,1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model to get train prediction\n",
    "pred = cross_val_predict(estimator=MemoryTagger(), X=tr_words, y=train_tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC       0.85      0.79      0.82      7140\n",
      "     B-MISC       0.85      0.73      0.79      3438\n",
      "      B-ORG       0.79      0.51      0.62      6321\n",
      "      B-PER       0.87      0.58      0.70      6600\n",
      "      I-LOC       0.71      0.59      0.65      1157\n",
      "     I-MISC       0.69      0.52      0.59      1155\n",
      "      I-ORG       0.72      0.48      0.58      3704\n",
      "      I-PER       0.72      0.46      0.56      4528\n",
      "          O       0.95      1.00      0.97    169578\n",
      "\n",
      "avg / total       0.92      0.93      0.92    203621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generate report on entire model\n",
    "report = classification_report(y_pred=pred, y_true=train_tags)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the test data set\n",
    "test_words, test_tags = extract_words(test)\n",
    "\n",
    "#tokenize words into tokens\n",
    "te_words = tokenize(test_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run model to get train prediction\n",
    "pred = cross_val_predict(estimator=MemoryTagger(), X=te_words, y=test_tags, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-LOC       0.83      0.66      0.74      1668\n",
      "     B-MISC       0.87      0.53      0.66       702\n",
      "      B-ORG       0.76      0.35      0.48      1661\n",
      "      B-PER       0.84      0.28      0.42      1617\n",
      "      I-LOC       0.65      0.44      0.53       257\n",
      "     I-MISC       0.78      0.51      0.62       216\n",
      "      I-ORG       0.62      0.33      0.43       835\n",
      "      I-PER       0.70      0.21      0.32      1156\n",
      "          O       0.90      1.00      0.95     38323\n",
      "\n",
      "avg / total       0.88      0.89      0.87     46435\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#generate report on entire model\n",
    "report = classification_report(y_pred=pred, y_true=test_tags)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
